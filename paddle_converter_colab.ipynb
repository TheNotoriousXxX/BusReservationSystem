{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheNotoriousXxX/BusReservationSystem/blob/terminator3.0/paddle_converter_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWIo37FrUybV",
        "outputId": "8bf76db9-a3ae-4396-b43d-f43ee1452d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.5/125.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.2/939.2 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.0/101.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.4/492.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.3/231.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.12.2 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://2ca33d219b70036aec.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        }
      ],
      "source": [
        "#@title ♻\n",
        "\n",
        "!pip install -q paddlepaddle==2.5.0rc0 paddlenlp==2.5.2 ppdiffusers==0.14.1 diffusers==0.14.0 safetensors==0.3.1 huggingface-hub==0.13.4 transformers==4.27.0\n",
        "!pip install -q omegaconf==2.3.0 fastcore==1.5.29 einops==0.6.1 gradio==3.19.1 numpy==1.22.4 lark==1.1.5 gdown==4.6.4 pytorch-lightning==2.0.2\n",
        "\n",
        "import os, gdown, gc\n",
        "import gradio as gr\n",
        "from ppdiffusers import StableDiffusionPipeline\n",
        "import paddle, torch\n",
        "from safetensors.torch import save_file, load_file\n",
        "from huggingface_hub import model_info, create_repo, create_branch, upload_folder\n",
        "from huggingface_hub.utils import RepositoryNotFoundError, RevisionNotFoundError\n",
        "\n",
        "def download_ckpt(ckpt_url, vae_url, is_safetensors):\n",
        "    if is_safetensors:\n",
        "        if \"drive.google.com\" in ckpt_url:\n",
        "            gdown.download(url=ckpt_url, output=\"model.safetensors\", quiet=False, fuzzy=True)\n",
        "        else:\n",
        "            os.system(f\"wget {ckpt_url} -O model.safetensors\")\n",
        "    else:\n",
        "        if \"drive.google.com\" in ckpt_url:\n",
        "            gdown.download(url=ckpt_url, output=\"model.ckpt\", quiet=False, fuzzy=True)\n",
        "        else:\n",
        "            os.system(f\"wget {ckpt_url} -O model.ckpt\")\n",
        "\n",
        "    if vae_url != \"\":\n",
        "        if \"drive.google.com\" in vae_url:\n",
        "            gdown.download(url=vae_url, output=\"vae.ckpt\", quiet=False, fuzzy=True)\n",
        "        else:\n",
        "            os.system(f\"wget {vae_url} -O vae.ckpt\")\n",
        "\n",
        "        model = torch.load(\"model.ckpt\", map_location=\"cpu\")\n",
        "        if \"state_dict\" in model:\n",
        "          sd = model[\"state_dict\"]\n",
        "        else:\n",
        "          sd = model\n",
        "        full_model = False\n",
        "        vae_model = torch.load(\"vae.ckpt\", map_location=\"cpu\")\n",
        "        vae_sd = vae_model['state_dict']\n",
        "        for vae_key in vae_sd:\n",
        "          if vae_key.startswith(\"first_stage_model.\"):\n",
        "            full_model = True\n",
        "            break\n",
        "        for vae_key in vae_sd:\n",
        "          sd_key = vae_key\n",
        "          if full_model:\n",
        "            if not sd_key.startswith(\"first_stage_model.\"):\n",
        "              continue\n",
        "          else:\n",
        "            if sd_key not in sd:\n",
        "              sd_key = \"first_stage_model.\" + sd_key\n",
        "          if sd_key not in sd:\n",
        "            continue\n",
        "          sd[sd_key] = vae_sd[vae_key]\n",
        "        torch.save(model, \"model.ckpt\")\n",
        "        del model\n",
        "        del vae_model\n",
        "        del sd\n",
        "        del vae_sd\n",
        "        gc.collect()\n",
        "    return \"download ckpt done!\"\n",
        "\n",
        "def to_paddle(is_safetensors):\n",
        "    if is_safetensors:\n",
        "        paddle_pipe = StableDiffusionPipeline.from_pretrained_original_ckpt(\"model.safetensors\")\n",
        "        paddle_pipe.save_pretrained(\"paddle\")\n",
        "    else:\n",
        "        paddle_pipe = StableDiffusionPipeline.from_pretrained_original_ckpt(\"model.ckpt\")\n",
        "        paddle_pipe.save_pretrained(\"paddle\")\n",
        "    del paddle_pipe\n",
        "    gc.collect()\n",
        "    return \"convert to paddle done!\"\n",
        "\n",
        "def pt_to_paddle(pt_url):\n",
        "    os.system(\"wget -q https://raw.githubusercontent.com/PaddlePaddle/PaddleNLP/v2.5.2/ppdiffusers/scripts/convert_diffusers_model/convert_diffusers_stable_diffusion_to_ppdiffusers.py -O convert_diffusers_stable_diffusion_to_ppdiffusers.py\")\n",
        "    os.system(\"sed -i 's/use_auth_token=True/use_auth_token=False/' convert_diffusers_stable_diffusion_to_ppdiffusers.py\")\n",
        "    os.system(f\"python3 convert_diffusers_stable_diffusion_to_ppdiffusers.py --pretrained_model_name_or_path {pt_url} --output_path paddle\")\n",
        "    return \"convert to paddle done!\"\n",
        "\n",
        "def push_paddle(model_to, token, branch):\n",
        "    try:\n",
        "        repo_exists = True\n",
        "        r_info = model_info(model_to, token=token)\n",
        "    except RepositoryNotFoundError:\n",
        "        repo_exists = False\n",
        "    finally:\n",
        "        if repo_exists:\n",
        "            print(r_info)\n",
        "        else:\n",
        "            create_repo(model_to, private=True, token=token)\n",
        "    try:\n",
        "        branch_exists = True\n",
        "        b_info = model_info(model_to, revision=branch, token=token)\n",
        "    except RevisionNotFoundError:\n",
        "        branch_exists = False\n",
        "    finally:\n",
        "        if branch_exists:\n",
        "            print(b_info)\n",
        "        else:\n",
        "            create_branch(model_to, branch=branch, token=token)\n",
        "    upload_folder(folder_path=\"paddle\", path_in_repo=\"\", revision=branch, repo_id=model_to, commit_message=f\"paddle - camenduru/converter\", token=token)\n",
        "    return \"push pt done!\"\n",
        "\n",
        "def delete_paddle():\n",
        "    os.system(f\"rm -rf paddle *.yaml model.safetensors model.ckpt\")\n",
        "    return \"delete paddle done!\"\n",
        "\n",
        "block = gr.Blocks()\n",
        "with block:\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### ckpt pytorch to ppdiffusers paddle\n",
        "    ckpt_url = <small>https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt or https://drive.google.com/file/d/file-id/view?usp=share_link or \"https://civitai.com/api/download/models/5616?type=Model&format=PickleTensor\"</small><br />\n",
        "    paddle_model_to = camenduru/openjourney <br />\n",
        "    branch = main <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_ckpt_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"ckpt_url\")\n",
        "                text_vae_url = gr.Textbox(show_label=False, max_lines=1, placeholder=\"vae_url\")\n",
        "                text_paddle_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"paddle_model_to\")\n",
        "                text_paddle_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"paddle_branch\")\n",
        "                text_paddle_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"🤗 token\")\n",
        "                out_paddle = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                is_safetensors = gr.Checkbox(label=\"Is Safetensors\", value=False)\n",
        "                btn_download_ckpt = gr.Button(\"Download CKPT\")\n",
        "                btn_to_paddle = gr.Button(\"Convert to ppDiffusers Paddle\")\n",
        "                btn_push_paddle = gr.Button(\"Push ppDiffusers Paddle to 🤗\")\n",
        "                btn_delete_paddle = gr.Button(\"Delete ppDiffusers Paddle\")\n",
        "        btn_download_ckpt.click(download_ckpt, inputs=[text_ckpt_url, text_vae_url, is_safetensors], outputs=out_paddle)\n",
        "        btn_to_paddle.click(to_paddle, inputs=[is_safetensors], outputs=out_paddle)\n",
        "        btn_push_paddle.click(push_paddle, inputs=[text_paddle_model_to, text_paddle_token, text_paddle_branch], outputs=out_paddle)\n",
        "        btn_delete_paddle.click(delete_paddle, outputs=out_paddle)\n",
        "    gr.Markdown(\n",
        "    \"\"\"\n",
        "    ### diffusers pytorch to ppdiffusers paddle <br />\n",
        "    pt_model_from = dreamlike-art/dreamlike-diffusion-1.0 <br />\n",
        "    paddle_model_to = camenduru/dreamlike-diffusion-1.0 <br />\n",
        "    branch = paddle <br />\n",
        "    token = get from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) new token role=write <br />\n",
        "    \"\"\")\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                text_pt_model_from = gr.Textbox(show_label=False, max_lines=1, placeholder=\"pt_model_from\")\n",
        "                text_paddle_model_to = gr.Textbox(show_label=False, max_lines=1, placeholder=\"paddle_model_to\")\n",
        "                text_paddle_branch = gr.Textbox(show_label=False, value=\"main\", max_lines=1, placeholder=\"paddle_branch\")\n",
        "                text_paddle_token = gr.Textbox(show_label=False, max_lines=1, placeholder=\"🤗 token\")\n",
        "                out_paddle = gr.Textbox(show_label=False)\n",
        "            with gr.Row().style(equal_height=True):\n",
        "                btn_to_paddle = gr.Button(\"Convert to ppDiffusers Paddle\")\n",
        "                btn_push_paddle = gr.Button(\"Push ppDiffusers Paddle to 🤗\")\n",
        "                btn_delete_paddle = gr.Button(\"Delete ppDiffusers Paddle\")\n",
        "        btn_to_paddle.click(pt_to_paddle, inputs=[text_pt_model_from], outputs=out_paddle)\n",
        "        btn_push_paddle.click(push_paddle, inputs=[text_paddle_model_to, text_paddle_token, text_paddle_branch], outputs=out_paddle)\n",
        "        btn_delete_paddle.click(delete_paddle, outputs=out_paddle)\n",
        "block.launch(share=True, inline=False, debug=True)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}